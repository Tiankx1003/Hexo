### 公司介绍

#### 0.地点

北京西城区 德外大街

#### 1.公司规模

月活跃用户1200万，

#### 2.主营业务

塔读文学：手机无线互联网原创文学先锋，精选海量精品小说，汇集各种经典读物，塔读文学陆续推出手机塔读WAP站、塔读Android客户端、塔读Symbian客户端、塔读Java客户端已支持2000多款手机，方便手机无线读者阅读和下载。
开奇应用商店：潮流的平台型手机软件。是基于Android平台的，集找应用、玩应用、管理应用为一体的平台型手机软件。

#### 3.日活量 日GMV

月活量500万，日活量200万，日均用户在线时长102.3分钟

深圳市宝安区新安街道海乐一路富铭花园 新安地铁站附近 

### 集群规模

12台服务器，128G内存 8T机械硬盘 2T固态硬盘 20核40线程 深信服虚拟化平台云服务器约4万/台(含服务)
### 框架结构
<!-- 手绘 -->
日志服务器，flume，kafka，hdfs，hive，mysql
业务数据库mysql sqoop hdfs hive
*实时需求sparkstreaming
即系查询 hbase impala kylin*

### 框架描述
#### 1.Flume
1. 单层1.7版本flume，12台服务器部署了四个flume节点
2. 日志服务器内的日志文件保存30天，flume使用tailDir Source，支持多目录和断点续传，1.6及以前的版本不支持，需要自定义source完成断点续传功能，MemoryChannel速度快可靠性低，FileChannel相反，我使用了KafkaChannel直接把数据存储到Kafka，省略了sink
3. flume通过take和put事务保证了数据采集的准确性
4. 我们使用了自定义interceptor分别完成了日志的类型区分和数据的轻量ETL(时间戳格式错误或json不完整的滤除)
5. 使用ganglia监控flume的事件try的次数success次数和总次数，try次数大于总次数时说明集群存在问题，可以在flume-env.sh中调节内存大小(默认1G)，如果不起作用可以考虑增加flume节点个数
 * 自定义拦截器的步骤
 * channel selector

#### 2.Kafka
1. 搭建kafka集群，日志服务器端的flume作为生产者，和kafka同一节点的flume作为消费者，根据集群的压测值和日常数据量的经验值确定了三台kafka，这个规模能够承受50M/s的速度
2. kafka的数据的副本个数是2，分区数(并发)为5，保存3天(默认7天)，大概数据量在60-70G/天
3. 我负责8个kafka topic(浏览，评论，收藏，启动，故障日志，消息通知，广告，内容推送)
4. 根据我们的业务性质，针对生产者的ack设置一直为1，leader收到数据后直接响应，也可以设置ack0，但是会很容易丢失数据，设置ack-1不丢数据但是会拉低集群性能(每个follower都收到)
5. 对于消费者我们使用的是range分区策略，经过长期使用检验，并没有发生严重的倾斜，所以一直没有更换为roundrobin，毕竟roundrobin限制较多，要求消费这线程数相同且消费者组只能消费同一个topic
6. kafka的副本同步队列ISR确保了leader挂掉后能有follower及时切换为leader，ISR主要的判断依据是同步数据的延迟时间，在旧的版本里还通过延迟条数来判断。
7. kafka还可以设置多目录来优化吞吐量
8. 内存我们一般设置为4G，高峰期(618，双11)会调节为6G

#### 3.HDFS
<!-- 读写流程 shuffle机制 hadoop优化 yarn调度 yarn任务提交  -->
1. HDFS作为集群的文件存储异同，在部署的时候要注意配置HA
2. 合理设置工作线程池个数(20 * log2(节点个数))，来优化通信
3. namenode的日志文件edits和镜像文件fsimages配置在不同的目录可以增加性能
4. namenode做多目录配置可以增加可靠性和吞吐量
<!-- 待补充 -->

#### 4.Hive
<!-- 架构 动态静态分区 四个by 窗口函数 时间系统函数 hive优化 -->
1. Hive作为数仓的重要工具，底层是MR程序，hive把sql语句转换为mr程序进行执行(mr直接编写较为复杂)
2. Hive的数据存储在hdfs，元数据放在mysql(因为默认的derby不支持多client)，为了避免mysql中的元数据信息损坏，要个mysql配置HA(keepalive)
3. 四个by 窗口函数 时间系统函数 hive优化

#### 5.数仓
1. 我们业务主要有物流相关的特快直送，国内保税仓发货，营销相关的特卖板块以及针对vip用户的专享活动和特价商品
2. 针对我们的数仓的输入源，我们将埋点产生的日志数据使用flume采集，使用kafka对接，mysql中的业务数据使用sqoop导出到hive
3. 使用sqoop对数据进行导入导出时需要注意几点，首先Sqoop底层是只有map没有reduce的maponly任务(默认四个)，任务的执行可能耗时很长，如果有个别任务失败就会导致最终结果不不正确，这种问题虽然能够通过调节sqoop默认的任务数为1来解决，但是会降低效率，这是可以使用--staging-table结合--clear-staging-table创建临时表的方式来实现整个导入导出任务的事务性；其次还要注意mysql和hive中对于空值的标记问题，mysql使用的是"null"，而hive中使用的"\N"，这是需要使用--null-string来解决
4. kafka主题，日志:浏览主题，广告，商品相关  业务:购物车，退货，物流信息，订单，评论主题，评价
5. 我们的数仓借鉴了阿里的分层方式，共分了四层:ods dwd dws ads
6. ods层存放原始数据不做改变，使用是列式存储和LZO压缩，根据日期进行分区；dwd层对数据做了清洗和脱敏(电话、身份证号、详细住址等)，对维度表进行了降维；dws层是对数据的轻度聚合，根据ads层的业务指标需要形成了宽边和拉链表；ads层主要是具体指标的实现，数据量较小，数据最终导入到mysql形成报表
7. 我们的数仓是基于维度建模，主要使用了星型模型，也存在少量的雪花模型
8. 表主要分为实体表，维度表，事实表，其中事实表又分为周期型事实表和事务型事实表。实体表主要是一些对象表(用户、商家、商品等)；维度表主要是知一些业务状态(商品的品类等级，编号的解释，如地区表，订单状态，支付方式，实名审批状态)；状态会有改变的事实表就是周期型事务表，已经确定不变的就是事务性事实表
9. 对于不同的表我们使用不同的同步策略(全量、增量、新增及变化、拉链表)

日志表: 商品点击，商品详情，商品详情页表，消息通知表
商品点击: 用户的基本信息字段，动作，商品id，种类等
商品详情页: 入口，上一页面来源，商品id，种类deng
广告表: 入口，内容，行为，展示风格等
错误日志: 错误详情
消息通知表: 通知类型，展示时间，展示内容等
 * 以上这些记录性质的，都是用每日增量表

业务表: 购物车，评分，订单表，订单详情表，退货表，用户表，商家表，商品分类表(一级，二级，三级)，支付流水，物流信息等
购物车详情: 用户id 商品id 商品价格 商家id 商品型号 商品分类等
 * 这类周期型事实表一般可以使用每日增量就可以了，到那时如果电商用户对某件商品用过之后，又想改评论，所以用每日新增及变化的方式实现同步

评论表: 评论时间，评论用户，评论商品，评论内容
 * 这个跟评分类似，也是用每日新增及变化的方式进行同步

订单表: 订单状态，订单编号，订单金额，支付方式，支付流水，创建时间等
 * 最好使用拉链表

<!-- 待补充 -->

**总结** 
1. 实体表不大，就可以做每日全量
2. 对于维度表，比如说商品分类，这种不是很大，也可以做每日全量，有些不会发生改变的维度就可以固定保存一份值(地区，种族)
3. 事务型事实表，比如说交易流水，操作日志，出库信息，这种每日比较大，且需要历史数据的，就根据时间做每日新增，可以利用分区表，每日做分区存储
4. 像这种周期型事实表的同步策略，比如订单表，有周期变化，需要反应不同时间点的状态，就需要做拉链表，记录每条信息的生命周期，一旦一条记录的生命周期结束就开始下一条的新纪录。把当前的日期放生效开始日期


**使用Hive实现的指标**
活跃(日活、周活、月活) 本周新增 留存用户比率 沉默用户量 流失用户量 本周回流用户量
最近一个月以内连续七天活跃用户量
最近三个月每周都有活跃的用户量

**使用Spark实现的指标**
漏斗分析 
VIP新增率
各年龄段平均用户平均在线时长
各年龄段日均阅读时长
各年龄段对应书籍分类top10 

**实时指标**(Spark Streaming & Flink)
每五分钟最近一小时内活跃用户数、阅读总量、热门书籍分类top3
一小时内广告点击、新用户率、新增VIP占比


数据健康问题

数据倾斜问题



